{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 25: Group-level Analysis 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 main parts to a statistical analysis:\n",
    "<ol>\n",
    "<li>Model - describes the parameters of the unknown distribution thought to be generating the data\n",
    "<li>Method - defines the loss function that is minimized in order to find the unknown model parameters\n",
    "<li>Algorithm - defines the manner in which the chosen loss function is minimized\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before performing group analysis, motion correction (intrasubject registration), spatial normalization (intersubject registration), and spatial smoothing (overcome limitations in spatial normalization)\n",
    "should be done.\n",
    "\n",
    "In group analysis we need the voxels to align across subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In level 1 we use the standard GLM analysis:\n",
    "<img src='level1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this level we have autocorrelated data, but we have a relatively large number of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can combine all of these subjects' data by concatenating the Y, X, beta, e, and V (covariance) matrices as follows:\n",
    "<img src='matrices.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we could fit each subjects data individually, but for simplicity in our records, we can write the full first-level model as:\n",
    "<img src='fulllevel1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write the full second level model as:\n",
    "<img src='fulllevel2.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $X_g$ is the second level design matrix (separating cases and controls) and $\\beta_g$ is the vector of second level parameters. In the second level we usually have independent and identically distributed data, but relatively few observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $X_g\\beta_g$ includes whether or not the subject is a case or control AND the amplitude for cases and controls. In matrix algebra this looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [0 1]] [3 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#create design matrix\n",
    "X_g = np.array([[1,0],[1,0],[0,1],[0,1]])\n",
    "#create parameter vector (case/control amplitudes)\n",
    "B_g = np.array([3,7])\n",
    "print(X_g, B_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 0]\n",
      " [3 0]\n",
      " [0 7]\n",
      " [0 7]]\n"
     ]
    }
   ],
   "source": [
    "#multiply the matrices to get the final beta vector\n",
    "XB_g = X_g * B_g\n",
    "print(XB_g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we can do this to relate subject specific parameters contained in in $\\beta$ to population parameters $\\beta_g$. We assume that the first level parameters are randomly sampled from a population of possible regression parameters, which allows us to generalize the results to the whole population.\n",
    "<img src='sourcepop.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given our summary equations for the two levels of models above, we can combine the two levels into a single level:\n",
    "<img src='mixedmodel.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "saying that Y follows a distribution with the above mean and variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the parameters of the above model, we need to define a loss function to minimize. \n",
    "\n",
    "In many cases Maximum Likelihood Estimation (MLE) or the Restricted Maximum Likelihood Estimation (RMLE) are used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Maximizes the likelihood of the <b>data</b>\n",
    "<li>Produces <b>biased</b> estimates of the variance components\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restricted Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li>Maximizes the likelihood of the <b>residuals</b>\n",
    "<li>Produces <b>unbiased</b> estimates of the variance components\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To minimize the lost function from above, we use an algorithm. In many cases these will be Newton-Raphson, Fisher-scoring, EM-algorithm, or IGLS/RIGLS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newton-Raphson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative procedure that finds estimates using the derivatives at the current solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fisher Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very similar to Newton-Raphson, but finds the estimates using Fisher Information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EM-algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iterative procedure that finds estimates from models that depend on unobserved latent variables such as the second level error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately, which methods and algorithms you use will depend on which software packages you decide to utilize. Different packages implement different algorithms like the ones discussed above. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different neuroimaging software packages have implemented different mixed-effects models. They differ in which methods and algorithms to use. \n",
    "\n",
    "But the most commonly used approach in fMRI analysis is a simple non-iterative two-stage least squares approach (the summary statistics approach). Recall that results from the first level are reused in the second level, reducing the computational burden of fitting an entire model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary Statistics Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "<li>Fit a model to each subject's data\n",
    "<li>Construct contrast images for each subject\n",
    "<li>Conduct a t-test on the contrast images\n",
    "</ol>\n",
    "\n",
    "However, only one contrast can be estimated at a time and only the contrasts, and NOT the variance components are recycled from level 1.\n",
    "\n",
    "<b>Assumptions</b>:\n",
    "<ul>\n",
    "<li>Homogeneous intra-subject variance\n",
    "<li>Balanced designs\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using temporal basis sets at the first level means it can be difficult to summarize the response with a single number, making group inference difficult.\n",
    "\n",
    "Instead, we can perform a group analysis using \n",
    "<ul>\n",
    "<li>the \"main\" basis function\n",
    "<li>all basis functions (and do an F-test)\n",
    "<li>re-parameterized fitted responses - recreate the HRF and estimate the magnitude, and use this information at the second level.\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
