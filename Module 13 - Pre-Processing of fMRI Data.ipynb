{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 13: Pre-Processing of fMRI Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fMRI data undergoes a series of pre-processing prior to analysis to validate model assumptions and identify and remove artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Goals</b>: \n",
    "<ol>\n",
    "<li>Minimize the influence of data acquisition and physiological artifacts\n",
    "<li>Check statistical assumptions and transform data to meet assumptions\n",
    "<li>Standardize locations of brain regions across subjects to achieve validity and sensitivity in group analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='pipeline1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Steps</b>:\n",
    "<ul>\n",
    "<li>Visualization and artifact removal\n",
    "<li>Slice time correction\n",
    "<li>Motion correction\n",
    "<li>Physiological Corrections\n",
    "<li>Co-registration\n",
    "<li>Normalization\n",
    "<li>Spatial filtering\n",
    "<li>temporal filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization and Artifact Removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should always be done first. It involves investigating the raw and image data to detect possible problems. Recall that fMRI data often contain transient spikes and slow drift artifacts. \n",
    "\n",
    "Principal Component Analysis (PCA) can be used to look for spike-related artifacts. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slice Time Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sample multiple slices of the brain during each individual repetition time (TR) to construct a voxel. Because these are collected sequentially, each slice is samples at a slightly different time point (2D imaging, not 3D). \n",
    "\n",
    "Slice time correction shifts each voxel's time series so that it appears that each sample occured simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine if we took all the green slices at the same time, all the yellow at another time, and all the blue at a third time below:\n",
    "<img src='stc.png'>\n",
    "\n",
    "Even though they are all pieces of the same signal, if we don't account for their timing, the results will appear something like this:<img src='stc1.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To account for this, we can use:\n",
    "<ol>\n",
    "<li><b>Temporal Interpolation</b> uses information from nearby time points to estimate the amplitude of the MR signal at the onset of each TR. This makes use of a linear, spline, or sinc function.\n",
    "<li><b>Phase Shift</b> applies a time shift to the Fourier Transform of the time series, which slides the time uniformly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is mostly to adjust for very small movements of the head during an experiment. Because we assume that a voxel depicts the same region of the brain at every point, head motion can make our results incorrect by making this assumption untrue.\n",
    "\n",
    "This can be corrected using a rigid body transformation, which assume that the brain is a rigid shape that may move around.\n",
    "\n",
    "<b>Note</b>: The goal of motion correction is to find the best alignment between an input image and some target image. To align the two, one needs to be transformed. The rigid body transformation involves 6 parameters: 3 sets of translations (x,y,z) and 3 sets of rotations (pitch,yaw,roll) which sums to 6 degrees of freedom.\n",
    "\n",
    "Types of transformations: <img src='trans.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Linear Transformations</b>\n",
    "<ul>\n",
    "<li>Rigid body (6 DOF): translation and rotation\n",
    "<li>Similarity (7 DOF): Translation, rotation, and a single global scaling\n",
    "<li>Affine (12 DOF): translation, rotation, scaling, and shearing\n",
    "</ul>\n",
    "<i>Warping</i> occurs when non-linear transformations relate the two images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target image is usually either the first image or the mean image of the fMRI time series. The goal is to find the set of parameters which minimize some cost function (usually sum of squared differences or mutual information) which assesses the similarity of the image and target."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Co-registration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a process of \"registering\" the structural MRI taken at the beginning of a session to the fMRI images. It allows us to visualize single-subject task activations overlaid on the individual's anatomical information. It also simplifies the transormation of the fMRI images to a standard coordinate system.\n",
    "\n",
    "Even though the statistics are performed on the low-resolution functional images, we may then present the findings on the high-res structural image where we can see better detail."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b> that there are differences between co-registration and motion correction. Functional and structural images do not have the same signal intensities in the same areas, so the 2 images cannot be subtracted from each other. \n",
    "\n",
    "Use at least an affine transformation to perform coregistration and the mutual information cost function. <img src='mutual.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Structural left, functional right, mapped onto same coordinate plane)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
