{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 21: Noise Models - AR Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last module we assumed that we had i.i.d noise, so we assumed the identity matrix for V, the covariance matrix. But in practice that's not usually reasonable. We typically have autocorrelation between adjacent time points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This noise is usually caused by physiological noise and low frequency drift that has not been appropriately modeled. To model this noise we typically use either an AR(p) or an ARMA(1,1) process. This is Auto-Regressive process of order p or and Auto Regressive Moving Average model of order (1,1) respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AR(1) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serial correlation can be modeled using a first-order autoregressive model: $$\\epsilon_t = \\phi \\epsilon_{t-1}+u_t$$\n",
    "\n",
    "with $u_t\\tilde{}N(0,\\sigma^2)$ where the error term $\\epsilon_t$ depends on the previous error term $\\epsilon_{t-1}$ and a new disturbance term $U_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autocorrelation function (ACF) for an AR(1) process at lag $h$ is:\n",
    "<img src='acf.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since the lag $h$ is 0 when comparing one point to itself, the phi value will be 1 here. Otherwise the autocorrelation is equal to phi which is some constant of the model, and then it decays according to phi to the power of h. Directly adjacent time points will have an autocorrelation of 0.7, but if they are 2 points apart it will be 0.49."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error Term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of V will depend on which noise model we use! When we assume the IID case, we are just using the identity matrix, but when we can't assume IID, we also have to calculate phi, and V is constructed using multiple phis:\n",
    "<img src='errorterm.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep in mind that we are creating this matrix V so that we can more accurately estimate obtain our estimate, fitted values, and residuals:\n",
    "<img src='glmsummary.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: In general the form of the covariance matrix is unknown, which means it needs to be estimated. So estimating V depends on the $\\beta$, but estimating $\\beta$ depends on V. \n",
    "\n",
    "This means we need an iterative procedure. Some methods include Method of Moments, Maximum Likelihood, and Restricted Maximum Likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterative Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way we could do this is the following:\n",
    "<ol>\n",
    "<li>Assume that V=I and calculate the OLS solution\n",
    "<li>Estimate the parameters of V using the residuals\n",
    "<li>Re-estimate the $\\beta$ values using the estimated covariance matrix $\\hat{V}$ from step 2.\n",
    "<li>Iterate until convergence\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we estimate V in an AR model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method of Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the <b>Yule-Walker estimates</b> which are a Method of Moments:\n",
    "Assume $\\epsilon_t$ is an AR(1) process,$$\\epsilon_t=\\phi\\epsilon_{t-1}+u_t$$\n",
    "\n",
    "for $t=0,\\pm1,...$ where $u_t\\tilde{}WN(0,\\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Yule-Walker estimates are:\n",
    "the auto covariance function $$\\hat{\\phi}=\\frac{\\hat{y}(1)}{\\hat{y}(0)}$$ and the variance $$\\hat{\\sigma}^2 = \\hat{y}(0)-\\hat{\\phi}\\hat{y}(1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maximum Likelihood Estimators (MLEs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are obtained by maximizing the log-likelihood:\n",
    "$$l^*(\\lambda)=-\\frac{1}{2}log(|V|)-\\frac{1}{2}(Y-X\\hat{\\beta})^TV^{-1}(Y-X\\hat{\\beta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\lambda$ are parameters associated with V. This is much more computationally heavy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Restricted Maximum Likelihood (ReML)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is similar to MLEs, but we maximize the restricted log-likelihood:\n",
    "$$l^*(\\lambda)=-\\frac{1}{2}log(|V|)-\\frac{1}{2}log(|X^TVX|)-\\frac{1}{2}(Y-X\\hat{\\beta})^TV^{-1}(Y-X\\hat{\\beta})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $\\lambda$ are parameters associated with V. Notice that the second term here is added on to the MLE equation and is the ReML term. The goal is to find the value of V that will make this term as large as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The differences between these two looks like this: \n",
    "<img src='mlreml.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatio-Temporal Behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same autocorrelation function will not hold true across the entire brain. The ACF will vary based on tissue type and location. So we have to fit an ACF for each voxel in the brain, which can be very computationally heavy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
